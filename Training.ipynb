{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b813e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36960300",
   "metadata": {},
   "source": [
    "## PPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc4177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch import multiprocessing\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import ParallelEnv, TransformedEnv, Compose, StepCounter \n",
    "from torchrl.envs.transforms import Transform, RemoveEmptySpecs\n",
    "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
    "from torchrl.modules import ProbabilisticActor, ValueOperator\n",
    "\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "from torchrl.objectives.value import GAE\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Environment.MazeEnv import TorchRLMazeEnv\n",
    "\n",
    "import uuid\n",
    "import os\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd75e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "num_cells = 256  # number of cells in each layer i.e. output dim.\n",
    "lr = 3e-4\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "batches = 1\n",
    "size = 4\n",
    "\n",
    "frames_per_batch = batches * size\n",
    "# For a complete training, bring the number of frames up to 1M\n",
    "total_frames = frames_per_batch * 256\n",
    "\n",
    "sub_batch_size = 32  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
    "num_epochs = 10# optimization steps per batch of data collected\n",
    "clip_epsilon = (\n",
    "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
    ")\n",
    "gamma = 0.99\n",
    "lmbda = 0.95\n",
    "entropy_eps = 1e-4\n",
    "\n",
    "# Environment hyper-parameters\n",
    "env_width = 128\n",
    "env_height = 72\n",
    "\n",
    "filename = \"\"\n",
    "\n",
    "runID = uuid.uuid4()\n",
    "\n",
    "runDir = f'./checkpoints/{runID}'\n",
    "\n",
    "os.mkdir(runDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af235e9",
   "metadata": {},
   "source": [
    "### Creating the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b586b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TorchRLMazeEnv(width=env_width, height=env_height, batches=batches, size=size, device=device, show_windows=True)\n",
    "\n",
    "# Add transforms in the correct order\n",
    "env = TransformedEnv(env, Compose( RemoveEmptySpecs(), StepCounter() ))\n",
    "\n",
    "# check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b01750",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b51dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNet(nn.Module):\n",
    "    def __init__(self, num_actions, num_cells=256):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "        )\n",
    "        \n",
    "        # Calculate the flattened size properly\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, env_height, env_width, device=device)  # Add batch dimension\n",
    "            n_flat = self.features(dummy).shape[1]  # Get the flattened size\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(n_flat, num_cells, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_cells, num_actions, device=device),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.features(x)\n",
    "        probs = self.head(x)\n",
    "        if len(probs.shape) == 3:\n",
    "            probs = probs.squeeze(0)\n",
    "        return probs\n",
    "\n",
    "# Create the actor and value operators as before\n",
    "actor = TensorDictModule(\n",
    "    module=ActorNet(6),\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"logits\"],\n",
    ")\n",
    "\n",
    "actor = ProbabilisticActor(\n",
    "    module=actor,\n",
    "    spec=env.action_spec,\n",
    "    in_keys=[\"logits\"],\n",
    "    distribution_class=Bernoulli,\n",
    "    distribution_kwargs={},\n",
    "    return_log_prob=True,\n",
    "    out_keys=[\"action\"],\n",
    ")\n",
    "\n",
    "value = ValueOperator(\n",
    "    module=ActorNet(1),\n",
    "    in_keys=[\"observation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f436a862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([4, 32, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        collector: TensorDict(\n",
       "            fields={\n",
       "                traj_ids: Tensor(shape=torch.Size([4, 32]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
       "            batch_size=torch.Size([4, 32]),\n",
       "            device=cuda:0,\n",
       "            is_shared=True),\n",
       "        done: Tensor(shape=torch.Size([4, 32, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        logits: Tensor(shape=torch.Size([4, 32, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([4, 32, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                observation: Tensor(shape=torch.Size([4, 32, 3, 72, 128]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                reward: Tensor(shape=torch.Size([4, 32, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                step_count: Tensor(shape=torch.Size([4, 32, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                terminated: Tensor(shape=torch.Size([4, 32, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "            batch_size=torch.Size([4, 32]),\n",
       "            device=cuda:0,\n",
       "            is_shared=True),\n",
       "        observation: Tensor(shape=torch.Size([4, 32, 3, 72, 128]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        sample_log_prob: Tensor(shape=torch.Size([4, 32, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        step_count: Tensor(shape=torch.Size([4, 32, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([4, 32, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "    batch_size=torch.Size([4, 32]),\n",
       "    device=cuda:0,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    actor,\n",
    "    frames_per_batch=128,\n",
    "    total_frames=total_frames,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(max_size=frames_per_batch, device=device),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=torch.Size([frames_per_batch]),\n",
    ")\n",
    "\n",
    "advantage_module = GAE(\n",
    "    gamma=gamma, lmbda=lmbda, value_network=value, average_gae=True, device=device,\n",
    ")\n",
    "\n",
    "loss_module = ClipPPOLoss(\n",
    "    actor_network=actor,\n",
    "    critic_network=value,\n",
    "    clip_epsilon=clip_epsilon,\n",
    "    entropy_bonus=bool(entropy_eps),\n",
    "    entropy_coef=entropy_eps,\n",
    "    critic_coef=1.0,\n",
    "    loss_critic_type=\"smooth_l1\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim, total_frames // frames_per_batch, 0.0\n",
    ")\n",
    "\n",
    "collector.rollout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375cea7d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f654737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1024 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [4, 32, 3, 72, 128]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: TensorDictModule failed with operation\n    ActorNet(\n      (features): Sequential(\n        (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n        (1): ReLU()\n        (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n        (3): ReLU()\n        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n        (5): ReLU()\n        (6): Flatten(start_dim=1, end_dim=-1)\n      )\n      (head): Sequential(\n        (0): Linear(in_features=3840, out_features=256, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=256, out_features=1, bias=True)\n      )\n    )\n    in_keys=['observation']\n    out_keys=['state_value'].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# we now have a batch of data to work with. Let's learn something from it.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# We'll need an \"advantage\" signal to make PPO work.\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# We re-compute it at each epoch as its value depends on the value\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# network which is updated in the inner loop.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43madvantage_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     flat_bs = tensordict_data.batch_size[\u001b[32m0\u001b[39m]                                 \u001b[38;5;66;03m# e.g. 64\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# 2) squeeze away any extra dims on obs first\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m#    (you said your obs was already [batch, C, H, W] here)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torchrl/objectives/value/advantages.py:79\u001b[39m, in \u001b[36m_self_set_skip_existing.<locals>.new_func\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_skip_existing(\u001b[38;5;28mself\u001b[39m.skip_existing):\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torchrl/objectives/value/advantages.py:68\u001b[39m, in \u001b[36m_self_set_grad_enabled.<locals>.new_fun\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fun)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.differentiable):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torchrl/objectives/value/advantages.py:1468\u001b[39m, in \u001b[36mGAE.forward\u001b[39m\u001b[34m(self, tensordict, params, target_params, time_dim)\u001b[39m\n\u001b[32m   1461\u001b[39m             target_params = params.clone(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1462\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hold_out_net(\u001b[38;5;28mself\u001b[39m.value_network) \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1463\u001b[39m         params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1464\u001b[39m     ) \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[32m   1465\u001b[39m         \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   1466\u001b[39m         \u001b[38;5;66;03m# we may still need to pass gradient, but we don't want to assign grads to\u001b[39;00m\n\u001b[32m   1467\u001b[39m         \u001b[38;5;66;03m# value net params\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1468\u001b[39m         value, next_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_value_nets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnext_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1472\u001b[39m \u001b[43m            \u001b[49m\u001b[43msingle_call\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshifted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1473\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensor_keys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdetach_next\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1475\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvmap_randomness\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvmap_randomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1478\u001b[39m     value = tensordict.get(\u001b[38;5;28mself\u001b[39m.tensor_keys.value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torchrl/objectives/value/advantages.py:534\u001b[39m, in \u001b[36mValueEstimatorBase._call_value_nets\u001b[39m\u001b[34m(self, data, params, next_params, single_call, value_key, detach_next, vmap_randomness, value_net)\u001b[39m\n\u001b[32m    527\u001b[39m     data_out = _vmap_func(\n\u001b[32m    528\u001b[39m         value_net,\n\u001b[32m    529\u001b[39m         (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m),\n\u001b[32m    530\u001b[39m         randomness=vmap_randomness,\n\u001b[32m    531\u001b[39m         pseudo_vmap=\u001b[38;5;28mself\u001b[39m.deactivate_vmap,\n\u001b[32m    532\u001b[39m     )(data_in, params_stack)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deactivate_vmap:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     data_out = \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmap_randomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    536\u001b[39m     data_out = _pseudo_vmap(value_net, (\u001b[32m0\u001b[39m,), randomness=vmap_randomness)(\n\u001b[32m    537\u001b[39m         data_in\n\u001b[32m    538\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/_functorch/apis.py:202\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/_functorch/vmap.py:334\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    324\u001b[39m         func,\n\u001b[32m    325\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         **kwargs,\n\u001b[32m    331\u001b[39m     )\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/_functorch/vmap.py:484\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    481\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    482\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    483\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    375\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1239\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1237\u001b[39m in_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1238\u001b[39m out_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.out_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1240\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1241\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1211\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1205\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1206\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSome tensors that are necessary for the module call may \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1207\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnot have not been found in the input tensordict: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1208\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1209\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1210\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1213\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensors_out \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_keys\n\u001b[32m   1214\u001b[39m ):\n\u001b[32m   1215\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1195\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1186\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m   1187\u001b[39m         tensordict._get_tuple_maybe_non_tensor(\n\u001b[32m   1188\u001b[39m             _unravel_key_to_tuple(in_key),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1192\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_keys\n\u001b[32m   1193\u001b[39m     )\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1197\u001b[39m         tensors_out = ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1154\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1152\u001b[39m kwargs.update(\u001b[38;5;28mself\u001b[39m.method_kwargs)\n\u001b[32m   1153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1154\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1156\u001b[39m     out = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.method)(*tensors, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mActorNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x.shape) == \u001b[32m3\u001b[39m:\n\u001b[32m     27\u001b[39m     x = x.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m probs = \u001b[38;5;28mself\u001b[39m.head(x)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(probs.shape) == \u001b[32m3\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/choice-playgrounds/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [4, 32, 3, 72, 128]"
     ]
    }
   ],
   "source": [
    "logs = defaultdict(list)\n",
    "pbar = tqdm(total=total_frames)\n",
    "eval_str = \"\"\n",
    "\n",
    "for i, tensordict_data in enumerate(collector):\n",
    "\n",
    "    tensordict_data = tensordict_data.squeeze(1) # Remove extra added dimension\n",
    "\n",
    "    # we now have a batch of data to work with. Let's learn something from it.\n",
    "    for _ in range(num_epochs):\n",
    "        # We'll need an \"advantage\" signal to make PPO work.\n",
    "        # We re-compute it at each epoch as its value depends on the value\n",
    "        # network which is updated in the inner loop.\n",
    "        advantage_module(tensordict_data)\n",
    "\n",
    "        flat_bs = tensordict_data.batch_size[0]                                 # e.g. 64\n",
    "\n",
    "        # 2) squeeze away any extra dims on obs first\n",
    "        #    (you said your obs was already [batch, C, H, W] here)\n",
    "        obs = tensordict_data[\"observation\"]             # [T, N, C, H, W]\n",
    "        obs = obs.reshape(flat_bs, *obs.shape[1:])       # [flat_bs, C, H, W]\n",
    "\n",
    "        # 3) grab event-shapes for the others\n",
    "        action_shape    = tensordict_data[\"action\"].shape[1:]          # e.g. [6]\n",
    "        logprob_shape   = tensordict_data[\"sample_log_prob\"].shape[1:] # e.g. [6]\n",
    "        # state_value, value_target, advantage are scalar => shape []\n",
    "\n",
    "        # 4) rebuild\n",
    "        flat_td = TensorDict(\n",
    "            {\n",
    "            \"observation\":    obs,\n",
    "            \"action\":         tensordict_data[\"action\"]\n",
    "                                    .reshape(flat_bs, *action_shape),\n",
    "            \"sample_log_prob\": tensordict_data[\"sample_log_prob\"]\n",
    "                                    .reshape(flat_bs, *logprob_shape),\n",
    "            \"state_value\":    tensordict_data[\"state_value\"]\n",
    "                                    .reshape(flat_bs, 1),\n",
    "            \"value_target\":   tensordict_data[\"value_target\"]\n",
    "                                    .reshape(flat_bs, 1),\n",
    "            \"advantage\":      tensordict_data[\"advantage\"]\n",
    "                                    .reshape(flat_bs),      # scalar event\n",
    "            },\n",
    "            batch_size=torch.Size([flat_bs]),\n",
    "            device=tensordict_data.device,\n",
    "        )\n",
    "        replay_buffer.extend(flat_td.cpu())\n",
    "\n",
    "        for _ in range(frames_per_batch // sub_batch_size):\n",
    "            subdata = replay_buffer.sample(sub_batch_size).to(device)\n",
    "            loss_vals = loss_module(subdata)\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            # Optimization: backward, grad clipping and optimization step\n",
    "            loss_value.backward()\n",
    "            # this is not strictly mandatory but it's good practice to keep\n",
    "            # your gradient norm bounded\n",
    "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
    "    pbar.update(tensordict_data.numel())\n",
    "    cum_reward_str = (\n",
    "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
    "    )\n",
    "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
    "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
    "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
    "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
    "    if i % 10 == 0:\n",
    "        # We evaluate the policy once every 10 batches of data.\n",
    "        # Evaluation is rather simple: execute the policy without exploration\n",
    "        # (take the expected value of the action distribution) for a given\n",
    "        # number of steps (1000, which is our ``env`` horizon).\n",
    "        # The ``rollout`` method of the ``env`` can take a policy as argument:\n",
    "        # it will then execute this policy at each step.\n",
    "        with set_exploration_type(ExplorationType.DETERMINISTIC), torch.no_grad():\n",
    "            # execute a rollout with the trained policy\n",
    "            eval_rollout = env.rollout(256, actor)\n",
    "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
    "            logs[\"eval reward (sum)\"].append(\n",
    "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
    "            )\n",
    "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
    "            eval_str = (\n",
    "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
    "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
    "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
    "            )\n",
    "            del eval_rollout\n",
    "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
    "\n",
    "    if i % (frames_per_batch * 8) == 0:\n",
    "        filename = f'{runDir}/{i}.ch'\n",
    "        checkpoint = {\n",
    "            'model_state_dict': actor.module.state_dict(),\n",
    "            'reward': logs[\"eval reward\"][-1],  # Assuming you have an optimizer\n",
    "            'epoch': i,  # Assuming you have an epoch counter\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, filename)\n",
    "        \n",
    "The above exception was the direct cause of the following exception:\n",
    "\n",
    "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
    "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
    "    scheduler.step()\n",
    "\n",
    "filename = f'{runDir}/_final.ch'\n",
    "checkpoint = {\n",
    "    'model_state_dict': actor.module.state_dict(),\n",
    "    'reward': logs[\"eval reward\"][-1],  # Assuming you have an optimizer\n",
    "    'epoch': i,  # Assuming you have an epoch counter\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{runDir}/logs.json', 'w') as f:\n",
    "    f.write(json.dumps(logs))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(logs[\"reward\"])\n",
    "plt.title(\"training rewards (average)\")\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(logs[\"step_count\"])\n",
    "plt.title(\"Max step count (training)\")\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(logs[\"eval reward (sum)\"])\n",
    "plt.title(\"Return (test)\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(logs[\"eval step_count\"])\n",
    "plt.title(\"Max step count (test)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23840d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for testing\n",
    "if filename == \"\":\n",
    "    filename = \"checkpoints/47d6adb5-3abd-4640-8b31-50a1b174142d/_final.ch\"\n",
    "\n",
    "l_checkpoint = torch.load(filename)\n",
    "\n",
    "actor.module.state_dict(l_checkpoint[\"model_state_dict\"])\n",
    "\n",
    "env = TorchRLMazeEnv(width=env_width, height=env_height, batches=1, size=1, device=device, show_windows=True)\n",
    "env = TransformedEnv(env, Compose( RemoveEmptySpecs(), StepCounter() ))\n",
    "\n",
    "env.rollout(512, actor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
